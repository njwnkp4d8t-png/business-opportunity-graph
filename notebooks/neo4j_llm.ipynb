{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c188613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install -U langchain-openai\n",
    "# !pip install -U langchain_neo4j\n",
    "# !pip install langchain_community\n",
    "# !pip install neo4j\n",
    "# !pip install shapely\n",
    "# !pip install -U pyproj\n",
    "# !pip install tqdm\n",
    "# !pip install langchain-community\n",
    "# !pip install -U pandas\n",
    "\n",
    "# !pip install -U langchain-neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1698fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "import psycopg2\n",
    "from neo4j import GraphDatabase\n",
    "from decimal import Decimal\n",
    "from shapely import wkb\n",
    "from pyproj import CRS, Transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f473e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials from .env file successfully loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "keys = [\"NEO4J_USER\", \"NEO4J_PASSWORD\",\"NEO4J_USER_LOCAL\", \"NEO4J_PASSWORD_LOCAL\"]\n",
    "for key in keys:\n",
    "    if key not in os.environ:\n",
    "        raise Exception(f\"Key '{key}' not found not in .env\")\n",
    "    \n",
    "print(\"Credentials from .env file successfully loaded\")\n",
    "\n",
    "NEO4J_LOCAL_DATABASE = \"busoppdse203\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbce2155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'n': {'name': 'Midtown', 'id': 60}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = Neo4jGraph(url=\"bolt://localhost:7687\",    username='neo4j',password='admin123',database=NEO4J_LOCAL_DATABASE )\n",
    "graph.query(\"MATCH (n) RETURN n LIMIT 1;\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14540937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "model_ver = \"gpt-4o\"\n",
    "model_provider = 'openai'\n",
    "model = init_chat_model(model_ver, model_provider=model_provider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beeca3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[dict]\n",
    "    answer: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49650fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve context \n",
    "# def retrieve(state: State):\n",
    "#     context = graph.query(\"CALL db.schema.visualization()\")\n",
    "#     return {\"context\": context}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    schema_map = graph.query(\"CALL apoc.meta.schema()\")\n",
    "    \n",
    "    context = schema_map \n",
    "    return {\"context\": context}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9fc0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd2ccb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the answer based on the question and context\n",
    "def generate(state: State):\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": state[\"context\"]})\n",
    "    response = model.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e35df1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define application steps\n",
    "workflow = StateGraph(State).add_sequence([retrieve, generate])\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1a9094a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Based on the context provided, I can answer the following types of questions:\n",
      "\n",
      "1. **Node Count Questions**:\n",
      "   - How many nodes exist for each type (e.g., Business, BlockGroup, City, etc.)?\n",
      "\n",
      "2. **Relationship Count Questions**:\n",
      "   - How many specific relationships exist (e.g., how many \"adjacent_to\" or \"contained_in\" relationships are there)?\n",
      "\n",
      "3. **Node Property Questions**:\n",
      "   - What properties are available for each node type (e.g., properties of Business, BlockGroup, etc.) and their data types?\n",
      "\n",
      "4. **Relationships Details**:\n",
      "   - What are the types and directions of relationships between node types (e.g., which nodes have \"contained_in\" or \"adjacent_to\" relationships)?\n",
      "\n",
      "5. **Node Uniqueness and Indexing**:\n",
      "   - Are properties of nodes unique or indexed?\n",
      "\n",
      "If you have questions within these areas, I can provide answers based on the context given.\n"
     ]
    }
   ],
   "source": [
    "# entity_type = 'BlockGroup'\n",
    "# question = \"How is the graph structured?\"\n",
    "\n",
    "\n",
    "\n",
    "question = \"What questions can you answer\"\n",
    "# question = f\"What attributes are available on a {entity_type} node\"\n",
    "# question = \"Are any cities contained in cities\"\n",
    "\n",
    "# question = 'What is the context'\n",
    "\n",
    "response = app.invoke({\"question\": question})\n",
    "print(\"Answer:\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657ed61c",
   "metadata": {},
   "source": [
    "# Text 2 Cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55b103d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "\n",
    "# Initialize the LLM\n",
    "model = init_chat_model(\n",
    "    \"gpt-4o\", \n",
    "    model_provider=\"openai\"\n",
    ")\n",
    "\n",
    "\n",
    "cypher_model = init_chat_model(\n",
    "    \"gpt-4o\", \n",
    "    model_provider=\"openai\",\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "\n",
    "# Connect to Neo4j\n",
    "graph = Neo4jGraph(\n",
    "    url=os.getenv(\"NEO4J_URI_LOCAL\"),\n",
    "    username=os.getenv(\"NEO4J_USER_LOCAL\"), \n",
    "    password=os.getenv(\"NEO4J_PASSWORD_LOCAL\"),\n",
    ")\n",
    "\n",
    "# Create the Cypher QA chain\n",
    "\n",
    "# Invoke the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28e6d491",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import GraphCypherQAChain\n",
    "\n",
    "# # Create the Cypher QA chain\n",
    "# cypher_qa = GraphCypherQAChain.from_llm(\n",
    "#     graph=graph, \n",
    "#     llm=model, \n",
    "#     allow_dangerous_requests=True,\n",
    "#     verbose=True, \n",
    "# )\n",
    "\n",
    "cypher_qa = GraphCypherQAChain.from_llm(\n",
    "    graph=graph, \n",
    "    llm=model, \n",
    "    cypher_llm=cypher_model,\n",
    "    allow_dangerous_requests=True,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7df4e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (c:Community)-[:contained_in]->(ci:City {name: \"San Diego\"})\n",
      "RETURN count(c) AS numberOfCommunities\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'numberOfCommunities': 157}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "There are 157 communities in San Diego.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Invoke the chain\n",
    "question = \"How many communities are there in San Diego\"\n",
    "\n",
    "response = cypher_qa.invoke({\"query\": question})\n",
    "print(response[\"result\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
